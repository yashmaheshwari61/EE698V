{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLDisQ6gAaMQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pwyZu2ibAhO1",
    "outputId": "01503b88-86a2-4619-d029-6ba8a7632cd8"
   },
   "outputs": [],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "#     print(X.shape)\n",
    "#     print(t.shape)\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_5__HzBks_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "    \n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    t_1hot=[]\n",
    "    for i in t_indices:\n",
    "        a=[0.0]*N\n",
    "        a[i]=a[i]+1\n",
    "        t_1hot.append(a)\n",
    "    t_1hot=np.array(t_1hot)\n",
    "    return t_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DsnXa89lIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_one_hot_encoding():\n",
    "    t_1hot = one_hot_encoding([0,2], 3)\n",
    "#     print(t_1hot[:,2])\n",
    "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
    "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
    "    print('Test passed', '\\U0001F44D')\n",
    "if __name__==\"__main__\":\n",
    "    test_one_hot_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXxxA2YkB_I8"
   },
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "    \n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    Nsamples=np.size(t,0)\n",
    "#     print(Nsamples)\n",
    "    Nsamples_test=int(testFraction*Nsamples)\n",
    "#     print(Nsamples_test)\n",
    "#     np.random.seed(4)\n",
    "#     n_test=np.random.randint(low=0, high=Nsamples-1, size=Nsamples_test)\n",
    "    n_random=np.random.permutation(Nsamples)\n",
    "    n_test=n_random[:Nsamples_test]\n",
    "#     n_test.sort()\n",
    "#     print(n_test)\n",
    "    X_train=[]\n",
    "    t_train=[]\n",
    "    X_test=[]\n",
    "    t_test=[]\n",
    "    for i in n_random:\n",
    "        if i in n_test:\n",
    "            X_test.append(X[i])\n",
    "            t_test.append(t[i])\n",
    "        else:\n",
    "            X_train.append(X[i])\n",
    "            t_train.append(t[i])\n",
    "#     print(X_test)\n",
    "    X_train=np.array(X_train)\n",
    "    X_test=np.array(X_test)\n",
    "    t_test=np.array(t_test)\n",
    "    t_train=np.array(t_train)\n",
    "#     print(X_train)\n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_splitData():\n",
    "    X = np.random.random((5,2))\n",
    "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
    "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
    "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
    "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK2lZ6ZpCjAg"
   },
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    mean=np.mean(X_train,axis=0)\n",
    "    std=np.std(X_train,axis=0)\n",
    "    X_train_normalized=(X_train-mean)/std\n",
    "    X_test_normalized=(X_test-mean)/std\n",
    "    return X_train_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_normalizeX():\n",
    "    X_train = np.array([[1,1,0],[2,2,1]])\n",
    "    X_test = np.array([[1,1,0],[3,3,2]])\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
    "    b = np.array([[-1.,-1.,-1.], [ 3., 3., 3.]])\n",
    "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
    "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_normalizeX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ_OSEoQLEuc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "    \n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y=1/(1+np.exp(-x))\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_sigmoid():\n",
    "    x = np.array([np.log(4),np.log(0.25),0])\n",
    "    y = sigmoid(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y=np.exp(x)\n",
    "    y=y/np.sum(y)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_softmax():\n",
    "    x = np.array([np.log(2),np.log(7),0])\n",
    "    y = softmax(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwi4QwxlOAOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape; it is sigmoid layer's output\n",
    "    Output:\n",
    "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "    y=x*(1-x).T\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        '''   \n",
    "        Input:\n",
    "            ni: int, size of input layer\n",
    "            nh: int, size of hidden layer\n",
    "            no: int, size of output layer\n",
    "        Action:\n",
    "            Creates instance variables\n",
    "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
    "        '''\n",
    "        self.ni = ni\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        self.Loss=[]\n",
    "        self.loss=0\n",
    "        return\n",
    "    \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Action:\n",
    "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
    "        '''\n",
    "        self.weights1=np.random.rand(self.nh,self.ni+1)\n",
    "        self.weights2=np.random.rand(self.no,self.nh+1)\n",
    "        ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "#         x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        return v2\n",
    "\n",
    "    def backprop(self,x,y,eta):\n",
    "        '''\n",
    "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
    "        Input:\n",
    "            x: numpy array of shape (ni,1)\n",
    "            y: numpy array of shape (no,1)\n",
    "            eta: learning rate\n",
    "        Action:\n",
    "            # Finding the derivatives\n",
    "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
    "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
    "\n",
    "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
    "              weights1 += eta*del_weights1\n",
    "              weights2 += eta*del_weights2\n",
    "        ''' \n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "#         x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        \n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        del_weights2=(y-v2)*v1.T\n",
    "        arr=(y-v2)*self.weights2\n",
    "        arr=np.delete(arr,0, axis=1)\n",
    "        arr=arr.sum(axis=0)\n",
    "        arr=np.array([arr])\n",
    "        del_weights1=np.dot((arr.T*(sigmoid(h1)*(1-sigmoid(h1)))),x.T)\n",
    "        self.weights2+=eta*del_weights2\n",
    "        \n",
    "#         print(arr.size)\n",
    "        self.weights1+=eta*del_weights1\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def fit(self, X, t, eta, epochs):\n",
    "        '''\n",
    "        input:\n",
    "            X: training input data \n",
    "            t: training targets\n",
    "            eta: learning rate\n",
    "            epochs: number of epochs\n",
    "        Action:\n",
    "            train the weights\n",
    "        '''\n",
    "\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        X = np.insert(X,0,1,axis=0)\n",
    "        for j in range(0,epochs):\n",
    "            self.loss=0\n",
    "            for i in range(0,X.shape[1]):\n",
    "                self.backprop(X[:,[i]],t[:,[i]],eta)\n",
    "            for i in range(0,X.shape[1]):\n",
    "                v2=self.predict(X[:,[i]])\n",
    "                self.loss+=(-1*np.sum(np.log(v2)*t[:,[i]]))\n",
    "            self.Loss.append(self.loss/X.shape[1])\n",
    "        plt.figure(figsize=(6,6))\n",
    "        plt.plot(self.Loss)\n",
    "        plt.title(\"Loss vs Epochs\")\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "    def predict_label(self,x):    \n",
    "        '''\n",
    "        Output:\n",
    "            y: np array of index\n",
    "        '''\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        \n",
    "        return np.argmax(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fmR8F2JIFwqm",
    "outputId": "fa868689-92c8-4a43-882f-3321cde1a301"
   },
   "outputs": [],
   "source": [
    "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
    "#printing the confusion matrix\n",
    "def getCM(y,t):\n",
    "    '''\n",
    "    Inputs:\n",
    "        y: estimated labels np array (Nsample,1)\n",
    "        t: targets np array (Nsamples,1)\n",
    "    Outputs:\n",
    "        CM : np array of confusion matrix\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "    CM=np.zeros((3,3))\n",
    "    for i in range(len(y)):\n",
    "        CM[np.argmax(t[i]),y[i]]+=1\n",
    "\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "Use the above functions to carry out the experiment:\n",
    "- load iris data and prepare it for NN\n",
    "- split randomly into 20% test data\n",
    "- create a NN with 1 hidden layer\n",
    "- train the network with training data\n",
    "- Plot loss w.r.t. number of epochs\n",
    "- Print confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hewsBv12weZ2",
    "outputId": "52407420-e7e5-4ca6-952b-6448ffe4b101",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.  0.  0.]\n",
      " [ 0. 11.  0.]\n",
      " [ 0.  0.  8.]]\n",
      "Accuracy = 100.0%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def experiment():\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
    "    X,Y=loadIrisData()\n",
    "    t=one_hot_encoding(Y,3)\n",
    "    NN=NeuralNetwork(4,10,3)\n",
    "    X_train, t_train, X_test, t_test=splitData(X,t,testFraction=0.2)\n",
    "    X_train, X_test=normalizeX(X_train, X_test)\n",
    "    X_train=X_train.T\n",
    "    t_train=t_train.T\n",
    "    X_test=X_test.T\n",
    "    NN.init_weights()\n",
    "    test=[]\n",
    "    NN.fit(X_train,t_train,0.02,400)\n",
    "    for i in range(0,X_test.shape[1]):\n",
    "        test.append(NN.predict_label(X_test[:,[i]]))\n",
    "    CM=getCM(test,t_test)\n",
    "    print(CM)\n",
    "    Accuracy=(CM[0,0]+CM[1,1]+CM[2,2])/X_test.shape[1]*100\n",
    "    print(\"Accuracy = \"+str(Accuracy)+\"%\")\n",
    "\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    experiment()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BP_Iris.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
