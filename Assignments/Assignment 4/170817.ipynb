{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "170817.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jLDisQ6gAaMQ",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.datasets import load_iris"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pwyZu2ibAhO1",
        "colab": {}
      },
      "source": [
        "def loadIrisData():\n",
        "    iris = load_iris()\n",
        "    X=iris['data']\n",
        "    t=iris['target']\n",
        "    return X, t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "48_5__HzBks_",
        "colab": {}
      },
      "source": [
        "def one_hot_encoding(t_indices, N):\n",
        "    '''\n",
        "    Inputs:\n",
        "        t_indices: list of indices\n",
        "        N: total no. of classes\n",
        "    '''\n",
        "    assert N>max(t_indices), (N, max(t_indices))\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
        "    t = []\n",
        "    for i in range(len(t_indices)):\n",
        "        temp = [0.0 for j in range(N)]\n",
        "        temp[t_indices[i]] = 1.0\n",
        "        t.append(np.array(temp))\n",
        "    t_1hot = np.array(t)\n",
        "    return t_1hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "m2DsnXa89lIk",
        "scrolled": true,
        "outputId": "24fb43aa-9629-47da-8d54-e9ae872aae0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_one_hot_encoding():\n",
        "    t_1hot = one_hot_encoding([0,2], 3)\n",
        "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
        "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
        "    print('Test passed', '\\U0001F44D')\n",
        "if __name__==\"__main__\":\n",
        "    test_one_hot_encoding()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VXxxA2YkB_I8",
        "colab": {}
      },
      "source": [
        "def splitData(X,t,testFraction=0.2):\n",
        "    \"\"\"\n",
        "    Use numpy functions only\n",
        "    Inputs:\n",
        "        X: np array of shape (Nsamples, dim)\n",
        "        t: np array of len Nsamples; can be one hot vectors or labels\n",
        "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
        "    \"\"\"\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
        "    X_train = X\n",
        "    t_train = t\n",
        "    test = np.int_(testFraction*(np.size(X,0)))\n",
        "    ntest = np.sort(np.array(np.random.choice(np.size(X,0)-1, test, replace=False)))\n",
        "    X_test = []\n",
        "    t_test = []\n",
        "    for i in range(len(ntest)):\n",
        "        X_test.append(X_train[ntest[i]-i])\n",
        "        t_test.append(t_train[ntest[i]-i])\n",
        "        t_train = np.delete(t_train,ntest[i]-i,0)\n",
        "        X_train = np.delete(X_train,ntest[i]-i,0)\n",
        "    t_test = np.array(t_test)\n",
        "    X_test = np.array(X_test)\n",
        "    return X_train, t_train, X_test, t_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjS3L2iVaCTL",
        "colab_type": "code",
        "outputId": "e4d52ec5-35dc-4e32-f259-1f3427975b36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_splitData():\n",
        "    X = np.random.random((5,2))\n",
        "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
        "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
        "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
        "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
        "    print('Test passed', '\\U0001F44D')    \n",
        "if __name__==\"__main__\":\n",
        "    test_splitData()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OK2lZ6ZpCjAg",
        "colab": {}
      },
      "source": [
        "### Normalize data to be of zero mean and unit variance\n",
        "def normalizeX(X_train, X_test):\n",
        "    '''\n",
        "    Inputs:\n",
        "        X_train: np array 2d\n",
        "        X_test: np array 2d\n",
        "    Outputs:\n",
        "        Normalized np arrays 2d\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
        "    X_train_normalized = (X_train - np.mean(X_train, axis = 0))/(np.std(X_train,axis = 0))\n",
        "    X_test_normalized = (X_test - np.mean(X_train, axis = 0))/(np.std(X_train,axis = 0))\n",
        "    return X_train_normalized, X_test_normalized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS27HMb0aCTY",
        "colab_type": "code",
        "outputId": "7a0ebaae-bb4c-47b5-c550-1da01b79f024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_normalizeX():\n",
        "    X_train = np.array([[1,1,0],[2,2,1]])\n",
        "    X_test = np.array([[1,1,0],[3,3,2]])\n",
        "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
        "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
        "    b = np.array([[-1.,-1.,-1.], [ 3., 3., 3.]])\n",
        "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
        "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
        "    print('Test passed', '\\U0001F44D')    \n",
        "if __name__==\"__main__\":\n",
        "    test_normalizeX()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AJ_OSEoQLEuc",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
        "    y = 1/(1 + np.exp(-x))\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PKGa-7ZaCTm",
        "colab_type": "code",
        "outputId": "89690379-8585-4857-e127-694a7eb0c26e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_sigmoid():\n",
        "    x = np.array([np.log(4),np.log(0.25),0])\n",
        "    y = sigmoid(x)\n",
        "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
        "    print('Test passed', '\\U0001F44D')    \n",
        "if __name__==\"__main__\":\n",
        "    test_sigmoid()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaTu1opgaCTv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax(x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape\n",
        "    Output:\n",
        "        y: numpy array of same shape as x\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
        "    y = (np.exp(x))/(np.sum(np.exp(x)))\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjaepW2CaCT3",
        "colab_type": "code",
        "outputId": "b5aceab0-ad39-4522-abfc-6f9c6293991a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def test_softmax():\n",
        "    x = np.array([np.log(2),np.log(7),0])\n",
        "    y = softmax(x)\n",
        "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
        "    print('Test passed', '\\U0001F44D')    \n",
        "if __name__==\"__main__\":\n",
        "    test_softmax()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test passed üëç\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Iwi4QwxlOAOR",
        "colab": {}
      },
      "source": [
        "def sigmoid_derivative(x):\n",
        "    '''\n",
        "    Input:\n",
        "        x: numpy array of any shape; it is sigmoid layer's output\n",
        "    Output:\n",
        "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
        "    y = (x)*(1-x)\n",
        "    return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5ORp5U-aCUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, ni, nh, no):\n",
        "        '''   \n",
        "        Input:\n",
        "            ni: int, size of input layer\n",
        "            nh: int, size of hidden layer\n",
        "            no: int, size of output layer\n",
        "        Action:\n",
        "            Creates instance variables\n",
        "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
        "        '''\n",
        "        self.ni = ni\n",
        "        self.nh = nh\n",
        "        self.no = no\n",
        "        self.weights1 = []\n",
        "        self.weights2 = []\n",
        "        return\n",
        "    \n",
        "    def init_weights(self):\n",
        "        '''\n",
        "        Action:\n",
        "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
        "        '''\n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 2 MARKS\n",
        "        self.weights1 = np.random.rand(self.nh,self.ni+1)\n",
        "        self.weights2 = np.random.rand(self.no,self.nh+1)\n",
        "    \n",
        "    def predict(self, x):\n",
        "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
        "        h1 = self.weights1.dot(x)\n",
        "        v1 = sigmoid(h1)\n",
        "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
        "        h2 = self.weights2.dot(v1)\n",
        "        v2 = softmax(h2)\n",
        "        return v2\n",
        "\n",
        "    def backprop(self,x,y,eta):\n",
        "        '''\n",
        "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
        "        Input:\n",
        "            x: numpy array of shape (ni,1)\n",
        "            y: numpy array of shape (no,1)\n",
        "            eta: learning rate\n",
        "        Action:\n",
        "            # Finding the derivatives\n",
        "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
        "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
        "\n",
        "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
        "              weights1 += eta*del_weights1\n",
        "              weights2 += eta*del_weights2\n",
        "        ''' \n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
        "        x = np.reshape(x,(np.size(x),1))\n",
        "        h1 = self.weights1.dot(x)\n",
        "        v1i = sigmoid(h1)\n",
        "        v1i = np.reshape(v1i,(np.size(v1i),1))\n",
        "        v1f = np.insert(v1i,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
        "        h2 = self.weights2.dot(v1f)\n",
        "        v2 = softmax(h2)\n",
        "        v2 = np.reshape(v2, (np.size(v2),1))\n",
        "        y = np.reshape(y, (np.size(y),1))\n",
        "        \n",
        "        del_weights2 = (y - v2)*(v1f.T)\n",
        "        \n",
        "        del_weights1 = ((np.transpose(np.delete(self.weights2,0,1))).dot(y-v2))*v1i*(1-v1i)*(np.transpose(x))\n",
        "        \n",
        "        self.weights1 += eta*del_weights1\n",
        "        self.weights2 += eta*del_weights2\n",
        "        return -np.sum((y)*(np.log(v2)))\n",
        "\n",
        "    def fit(self, X, t, eta, epochs):\n",
        "        '''\n",
        "        input:\n",
        "            X: training input data \n",
        "            t: training targets\n",
        "            eta: learning rate\n",
        "            epochs: number of epochs\n",
        "        Action:\n",
        "            train the weights\n",
        "        '''\n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
        "        loss = []\n",
        "        temp = 0\n",
        "        index = 0\n",
        "        ind = np.arange(np.size(X,0))\n",
        "        np.random.shuffle(ind)\n",
        "        for i in range(epochs):\n",
        "            for j in ind:\n",
        "                temp += self.backprop(np.transpose(X[j]),np.transpose(t[j]),eta)\n",
        "                index +=1\n",
        "            loss.append(temp/index)\n",
        "            temp = 0\n",
        "        plt.plot(loss)\n",
        "        plt.xlabel(\"Number of Epochs\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        \n",
        "    def predict_label(self,x):    \n",
        "        '''\n",
        "        Output:\n",
        "            y: np array of index\n",
        "        '''\n",
        "\n",
        "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
        "        y = []\n",
        "        Y = self.predict(x)\n",
        "        for i in range(np.size(Y,axis=1)):\n",
        "            y.append(np.argmax(Y[:,i]))\n",
        "        y = np.array(y)\n",
        "        return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fmR8F2JIFwqm",
        "colab": {}
      },
      "source": [
        "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
        "#printing the confusion matrix\n",
        "def getCM(y,t):\n",
        "    '''\n",
        "    Inputs:\n",
        "        y: estimated labels np array (Nsample,1)\n",
        "        t: targets np array (Nsamples,1)\n",
        "    Outputs:\n",
        "        CM : np array of confusion matrix\n",
        "    '''\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
        "    n = np.size(np.unique(t))\n",
        "    CM = np.zeros((n,n))\n",
        "    for i in range(len(t)):\n",
        "        CM[t[i],y[i]]+=1\n",
        "    accuracy = ((np.sum(np.diagonal(CM)))/(np.sum(CM)))*100\n",
        "    print(\"Accuracy = \",accuracy)\n",
        "    print(CM)\n",
        "    return CM"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FsWOCCYaCUS",
        "colab_type": "text"
      },
      "source": [
        "#### Experiments\n",
        "Use the above functions to carry out the experiment:\n",
        "- load iris data and prepare it for NN\n",
        "- split randomly into 20% test data\n",
        "- create a NN with 1 hidden layer\n",
        "- train the network with training data\n",
        "- Plot loss w.r.t. number of epochs\n",
        "- Print confusion matrix on test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hewsBv12weZ2",
        "outputId": "b6aadc4e-fcbe-4783-9e38-720fdd646349",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "def experiment():\n",
        "\n",
        "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
        "    X,t = loadIrisData()\n",
        "    X_train, t_train, X_test, t_test = splitData(X,t,0.2)\n",
        "    X_train,X_test = normalizeX(X_train, X_test)\n",
        "    N = NeuralNetwork(np.size(X,1),5,np.size(np.unique(t)))\n",
        "    N.init_weights()\n",
        "    N.fit(X_train,one_hot_encoding(t_train,np.size(np.unique(t))),0.01,100)\n",
        "    y = N.predict_label(np.transpose(X_test))\n",
        "    getCM(y,t_test)\n",
        "    \n",
        "if __name__==\"__main__\":\n",
        "    experiment()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy =  90.0\n",
            "[[ 5.  0.  0.]\n",
            " [ 0. 14.  2.]\n",
            " [ 0.  1.  8.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmVmdQ8HMzOocCmZmVudQMDOzuv8PTS20febvHSgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkCB7F_B_2Yo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}